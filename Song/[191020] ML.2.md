# [191020] ML.2

#### Metric Learning

Metric = function = distance or similarity

Metric is mapping function

- non negativity
- symmetry
- triangle inequality
- identity of indiscernible

컨셉: 유사도를 학습하자!

- Face identification

- Visual tracking - 비디오에서 같은 객체를 계속 찾기

  t~t+1 의 유사도를 t~t+2보다 높다고 학습해야한다.

- Information Retrieval
- Recommender System - feature 유사도를 계산해서 space를 줄인다.



#### Classical(non-deep) Metric Learning

1. Euclidean Distance

   - 고차원에서는 적합한 거리를 찾지 못한다.

   - 대안: eigenvalue component 축을 찾아서 각 축에 대해 re-scaling 작업

     = <b>Mahalanobis Distance</b>

     -> Learning M(scaling factor)

- A first approach to distance metric learning(2002)

  - 같은 클라스에 대해서 argmin(M)을 만들고 다른 클라스에 대해서는 1이상이 되도록 학습

  

- Large Margin Nearest Neighbor(2006)

  - data = i,j,l
  - M = argmin( n(i,j) * distance(i,j)  ) + constant * n(i,j) * (1 - n(i,l)) * hinge
    - hinge = max(0, 1 + d(i,l) - d(i,l))
    - i,j 가 유사할 때, i와 j의 거리를 줄이는 M이 학습
    - i,l 이 유사하면 아무 일x
    - i,l 이 유사하지 않을 때 + hinge 가 0보다 클때 -> M이 학습



#### Deep Metric Learning

<b>학습은 classfication을 잘 하도록 학습되는게 아니라, 높은 simillarity를 갖도록 학습</b>

= 마지막 fully connected layer에 들어가기 전의 여러 뉴런들에게서 나온 Output의 <b>distance</b>

= Euclidean distance로 유사도를 표현하기 적합한 방식으로 f가 학습된다.

- <b>Siamese Network</b>

  - Contrastive loss: pair-wise loss for metric learning

  - Learning the Siamese network

    - Distance measure D: Squared Euclidean distance

    - Minimization of L(W,y,x 1,x 2) with respect to W

    - W = argmin(L)

    - Trained by gradient-descent

      

- <b>Triplet Network</b>

  - Pair-wise relation을 넘어, triplet relation을 학습하자
  - i = anchor, j = positive, l = negative
  - Loss = MAX(0, D(x(i),x(j)) - D(x(i),x(l)) + delta )



#### Tips for Metric Learning:

#### Normalization Matters

- Very Important for suitable Margin

#### Sample Selection Also Matters

- Cost가 너무 커서 학습에 필요한 pairs를 뽑는 것이 중요하다
- Easy negative - Positive들보다 확실히 멀면서 margin보다는 가까운 데이터
- Hard negative - Positive들 사이 어딘가에 존재
  - 너무 Hard한 sample들을 뽑으면 로스가 너무 커져서 학습을 방해한다
- <b>Sampling Matters in Deep Embedding Learning(2017)</b>
  - Distance weighted sampling





