# [191124] ML. 6

#### Few-Shot Learning, Meta Learning (MAML)

- Success = Big Data + Powerful Model + Computational Power



#### Learning From Scarce Data

How to achieve good generalization from only a small amount of the supervision?

- Domain Adaptation: transfer knowledge from another domain
- Semi-supervised Learning: utilize both labeled & unlabeled data
-  ...



#### Few Shot Learning - 시나리오

- One Shot Learning
  - learning from one example per each class
  - Human can learn very quickly form very small data



- Training a model with a very small amount of training data
  - K shot learning: there exist only k instances per each class
- Why do we need few-shot learning?
  - Because human can!



- Zero-shot learning? (ex) zebra is a kind of horse with black-white strip
  - horse & strip에 대한 정보만으로 zebra를 맞출 수 있을까?



#### Meta Learning - 기법 중 하나

meta learning: learning to learn

= Aim to train a model that can rapidly adapt to a new task

= 트레인 과정에서 경험하지 못했던 태스크에 대해 빠르게 학습(적응) 되는 것



Meta Learning의 task는 {트레인 셋의 인스턴스 집합}을 학습하는 것

따라서, 각 데이터는 {집합}이다. Train Set: {지도 태스크 집합} / Test Set: {지도 태스크 집합}



<b>목적: 각 태스크를 잘하는 것 X, 학습을 잘하는 것</b>

Transfer Learning: pre-training

상위 layer의 parameter를 Freeze해서 금방 학습에 성공하는 것

= pre-train network on image classification, the fine-tune network on new task

 <b>Manifold of images have a consistent structure even between different tasks</b>



[논문 리뷰 1]

#### Model-Agnostic(무관한) Meta-Learning (ICML 17)

We consider a model f(x)

- during meta-learning, the model is trained to learn fast

- For task T(i) model's parameter theta become
  - theta(i) = theta - learning rate * differential(loss)

- The goal is minimize the below objective function

  - min (  sigma  (  loss( theta(i)))) = 지금 시점이 아니라 다음 시점의 로스를 최소화하는 방향 

    (vs)  min( sigma ( loss (theta))) = multi-task learning loss

- multi-task learning loss와 향하는 방향은 비슷한데, 이후의 로스도 고려하여 업데이트된다.



<b>multi task learning loss</b> 왜 사용?

- 정규화의 역할을 수행한다
- 한 태스크에 오버피팅하는 것을 막는다



Experiment

- Regression
  - sine wave fitting
    - meta training(700,000)





[논문 리뷰 2]

추천 시스템에서,

Many shot class == interaction이 많은 유저,

Few shot class == interaction이 별로 없는 유저

-  각 Task를 각 유저의 rating prediction으로 보고, 이 모델을 적용하면,

  ​	적은 수의 interaction 정보로, 유저의 취향을 가장 잘 학습하는 learner를 학습할 수 있겠다!



MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation (KDD 2019)

- Task
  - 각 유저별로 평점을 제공하는 모델이 제공되기 때문에 multi task problem

- Motivation

  - Providing accurate recommendations to cold-start users is challenging

- Rating Predictor

  - user vector + item vector -- predict score

- Evidence Candidate Selection

  - Provide personalized item sets to cold-start users
  - 로스를 최소로 감소시키는 영화 아이템 셋을 고른다

  

