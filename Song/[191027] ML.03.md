# [191027] ML. 3

#### Advanced Metric Learning

metric learning + domain adaptation -> <b>sscdr</b> -> recommender system

- <b>Evaluation Metrics</b>
- 모델의 성능을 평가하기 위해서 사용됨
  - Regression
    - RMSE(root mean squared error)
    - MAE(mean absolute error) - 이상치에 덜 민감
  - Classfication
    - Accuracy = ( tp + tn ) / total number
      - 데이터의 class balance에 아주 민감하다
    - Precision & Recall
      - Recall = tp / number of positive
      - Precision = tp / number of predicted positive
    - Ranking
      - 정답 ground truths set: 순서의 개념이 없다
      - Model의 결과 ranking list: 순서의 개념이 있다
      - <b>NDCG Metric</b>
        - 더 높은 랭크에서 정답을 맞췄을 때 가중치를 줌
        - 스코어링의 성능까지도 평가할 수 있는 metric



- Deep Metric Learning
  -  Distance metric을 고정하고, similarity를 극대화하는 feature extractor 학습
  - Normalization Matters
    - without the normalization, the margin becomes trivial
  - Sampling also matters
    - Negative sample을 적절히 semi-hard하게 뽑는 것이 좋다



- Triplet ranking loss for a triplet ( anchor, pos, neg) // Since 2015~

Paper 1. Deep Metric Learning with Angular Loss (17)

Paper 2. Multi-Object Tracking with Quadruplet CNN (17)

Paper 3. A deep quadruplet network for person re-identification (17) 

Paper 4. Deep Metric Learning Beyond Binary Supervision (19)



#### Paper 1

Angular Loss = Gradient Descent 과정에서 각 sample의 반대 방향으로 학습

단점: Triple 안의 pair-wise관계만 반영한다. -> Positive와 Negative의 관계를 학습x

<b>Key Idea</b> anchor-pos & anchor-neg + pos-neg도 함께 고려해야 한다.

- 해당 관계를 만족하는 triangle에서, angular n은 가장 작은 각을 갖는다
- 따라서 angular n에 upper constraint를 둠으로써, 위와 같은 관계를 반영하자
- 문제: angular n을 minimize하도록 학습하면, similarity가 제대로 학습되지 않는다

Proposed Method

1. Define a circum circle C that has a center x(c)
2. Define a hyperplane P (1)intersect the center of C (2)perpendicular to e(nc)
3. Constraing e(nm) , their loss function is defined by tan(e(nc))

Loss = (x(a) - x(p))^2 - 4tan^2 x alpla x (x(n) - x(c))^2



-> Paper 1의 한계점 보완

#### Paper 3

단점: The relationship among a triplet is not sufficient

Task: Person re-identification = 보여지는 관점이 다를 때 어떻게 같은 사람이라 판단?

<b>Quadruplet Network 1</b>

- Enlarging inter-class distances with additional constraints for better generalization
- 같은 클래스 내에서도 그룹을 나누어서 같은 그룹끼리 더 가깝게 만들어야한다.

해결책 ==>> triplet loss -> quadruplet loss

- Quadruplet rank loss
  - A typical form: A linear combination of two triplet rank losses
  - Paper Novel Loss
    - 기존 triplet distance +
    - <b>max( Inter-class dist - Intra-class loss + lambda)</b>
  - This loss makes classes latent features to be distinguishable



#### Paper 2

- 기존 triple loss는 multi-object tracking task 에서 불완전하다

#### Quadruplet Network 2

1. object presentation
2. target indication
3. target indication removed - 무작위 이동
4. track objects

- the relationship among a triplet is not sufficient

  - different relationships among positive sample according to their time indices
  - Positive 샘플간의 가까운 정도도 Loss로 학습해야한다!

- Paper Novel Loss

  - max( anchor-pos1 dist  - anchor-pos2 dist + lambda 1 ) +
  - max( anchor-pos2 dist - anchor-neg dist + lambda 2)
  - positive samples closer in time should be placed closer to the anchor

  단점: hyper-parameter가 너무 많다 lambda 1을 lambda 2보다 작게 설정



#### Paper 4

- 기존 Metric Learning을 두 개의 클라스가 같은지 아닌지만 분류했다
- Similar Score에 대한 정보를 반영하지 못한다

Data: 모든 이미지간의 pair distance가 주어진다.

- Easy Idea. N-th plet loss 로스의 항을 확장

- Paper Novel Idea

  - Approximate the ration of label distances 

    by the ratio of distances in the latent feature space

- Feature Space의 유사 정도가 Label Space의 유사 정도와 일치하도록 학습

- <b>No need to use the margin, No need to normalize</b>

- Loss: log( D(f(a),f(i)) / D(f(a),f(j)) ) - log( D(y(a),y(i)) / D(y(a),y(j)) ) ^ 2



#### Intro. to recommender System

Metric Learning in Recommender System

<B>Recommender Systems Overview</B>

Let the user-item rating matrix denote as R (m x n)

- m: number of users
- n: number of items

Explicit feedbacks / implicit feedbacks (binary)

1. Unobserved item에 대한 평점을 예측하고
2. 내림차순으로 정렬하여, 순서대로 보여주자



- K-Nearest Neighbor
  - user u의 rating vector = r(u)
  - r(d)와 가장 유사한 k 개의 user rating vector들을 찾고, 그 vector들의 weight sum

- Latent Factor Model

  - 각 user와, 각 item에 해당하는 latent vector를 만들고, rating을 latent vector 간의

    interaction으로 표현하도록 학습하자.

    1. Matrix Factorizaiton (MF) - 2009

       - Matrix R -> P x Q.T
       - P의 각 row는 각 유저의 latent vector, Q의 각 col은 각 아이템의 latent vector
       - latent vector 간의 inner product로 유저의 선호를 예측

    2. Metric Learning - 2017

       왜 굳이 Metric Learning이 추천 시스템에 쓰여야 하나?

- <b>Collaborative Metric Learning (2017)</b> Paper

Simple triplet loss 유저의 latent vector는 구입한 적이 없는 아이템보다 구매한 아이템에 가깝

Inner product를 L2 distance로 바꿈으로서 성능이 높아졌다.



- 